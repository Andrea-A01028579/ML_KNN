{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTY76UCz2Z4A"
      },
      "source": [
        "# KNN implementation on Kaggle dataset\n",
        "\n",
        "For this implementation a kaggle dataset is used, with the aim of predicting a students droupout or academic success rates. The link to the data set is: [link](https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention). In order for the code to run, upload the dataset to the colab workspace, or into google drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2yfUdnj18Xe"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hmzq_qpGvrh0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsjMV5H82PFL"
      },
      "source": [
        "## External methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oFLtJk_Wazl4"
      },
      "outputs": [],
      "source": [
        "#Other methods that don't need to belong to the class\n",
        "\n",
        "def euclidean_distance(x1,x2): #for euclidean distance\n",
        "  return np.sqrt(np.sum((x1-x2)**2))\n",
        "\n",
        "def manhattan_distance(x1,x2): #for manhattan distance\n",
        "  return np.sum(np.abs(x1-x2))\n",
        "\n",
        "def mahalanobis_distance(x1,x2,cov_inv): #mahalanobis distance\n",
        "  #cov_inv = np.linalg.inv(np.cov(X_train, rowvar=False)) passed directly from fit so its not calculated each time\n",
        "  return np.sqrt(np.dot(np.dot((x1-x2), cov_inv), (x1-x2)))\n",
        "\n",
        "def cosine_similarity(x1,x2):\n",
        "  return np.dot(x1,x2)/(np.linalg.norm(x1)*np.linalg.norm(x2))\n",
        "\n",
        "def most_common(values): #for classification target\n",
        "  counts={}\n",
        "  for item in values:\n",
        "    counts[item]=counts.get(item, 0)+1\n",
        "  sorted_counts=sorted(counts.items(),key=lambda x: x[1], reverse=True)\n",
        "  return sorted_counts[0][0]\n",
        "\n",
        "def calculate_distance(x1,x2,metric,cov_inv):\n",
        "  if metric=='euclidean':\n",
        "    return euclidean_distance(x1,x2)\n",
        "  if metric=='manhattan':\n",
        "    return manhattan_distance(x1,x2)\n",
        "  if metric=='mahalanobis':\n",
        "    return mahalanobis_distance(x1,x2,cov_inv)\n",
        "  if metric=='cosine similarity':\n",
        "    return cosine_similarity(x1,x2)\n",
        "  if callable(metric):\n",
        "    try:\n",
        "      return metric(x1, x2)\n",
        "    except ValueError as e:\n",
        "      print('Error in callable function: ',e)\n",
        "\n",
        "\n",
        "def find_target(nearest_y_value,target):\n",
        "  if target=='classification':\n",
        "    return most_common(nearest_y_value)\n",
        "  if target=='regression':\n",
        "    return np.mean(nearest_y_value)\n",
        "\n",
        "def class_accuracy(y_pred, y_test):\n",
        "    error=0\n",
        "    for i in range(len(y_pred)):\n",
        "      if y_pred[i]!=y_test[i]:\n",
        "        error=error+1\n",
        "    return (len(y_pred)-error)/len(y_pred)*100\n",
        "\n",
        "def reg_accuracy(y_pred, y_test, dev):\n",
        "  error=0\n",
        "  for i in range(len(y_pred)):\n",
        "    if abs(y_pred[i]-y_test[i])>dev:\n",
        "      error=error+1\n",
        "  return (len(y_pred)-error)/len(y_pred)*100\n",
        "\n",
        "def mean_squared_error(y_pred, y_test):\n",
        "  squared_errors = (y_test - y_pred) ** 2\n",
        "  mse = np.mean(squared_errors)\n",
        "  return mse\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo6S_meB2XjR"
      },
      "source": [
        "## Class definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e2aYjT9LZS7q"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "\n",
        "  def __init__(self, k=5, metric='euclidean',target='classification', dev=None):\n",
        "    #Parameter fail safes\n",
        "    if not isinstance(k, int) or k <0:\n",
        "      raise ValueError('k must be a non-negative integer')\n",
        "    possible_metrics={'euclidean', 'manhattan','mahalanobis', 'cosine similarity'}\n",
        "    if not (isinstance(metric, str) and metric in {'euclidean', 'manhattan', 'mahalanobis', 'cosine similarity'} or callable(metric)):\n",
        "      raise ValueError('Invalid metric. Allowed metrics are \\'euclidean\\' , \\'manhattan\\',\\'mahalanobis\\'or \\'cosine similarity\\'; or a callable function')\n",
        "    possible_targets={'classification', 'regression'}\n",
        "    if target not in possible_targets:\n",
        "      raise ValueError('Invalid target. Allowed metrics are \\'classification\\' or \\'regression\\'')\n",
        "    if (not isinstance(dev, int) or dev <0) and (dev is not None):\n",
        "      raise ValueError('Standard deviation must be a non-negative integer')\n",
        "\n",
        "\n",
        "\n",
        "    self.k=k #parameter amount of neighbors\n",
        "    self.metric=metric #parameter type of metric\n",
        "    self.target=target #parameter target (classification or regression)\n",
        "    try: #parameter deviation for accepted deviation in regression models, if it isnt regression this parameter doesnt exist\n",
        "      if target=='classification' and dev!=0 and (dev is not None):\n",
        "        self.dev=None\n",
        "        raise ValueError(\"Deviation won't be used in classification models, parameter ignored\")\n",
        "      else:\n",
        "        self.dev=dev\n",
        "    except ValueError as e:\n",
        "      print(e)\n",
        "    self.cov_inv=0\n",
        "\n",
        "  def fit(self, X, y): #fit in KNN stores the data to compare the given point\n",
        "    self.X_train=X\n",
        "    self.y_train=y\n",
        "    if self.metric=='mahalanobis':\n",
        "      self.cov_inv=np.linalg.inv(np.cov(X, rowvar=False))\n",
        "    #check that k<than amount of data points\n",
        "    if self.k>len(X):\n",
        "      raise ValueError(\"k is bigger than the amount of data points, recreate KNN with a different k, or add more data\")\n",
        "\n",
        "\n",
        "\n",
        "  def predict(self, X): # calls make prediction method for each point of X\n",
        "    y_pred=[self.make_prediction(x) for x in X]\n",
        "    return np.array(y_pred)\n",
        "\n",
        "\n",
        "  def make_prediction(self, x):\n",
        "    #calculates the distance depending on the metric chosen\n",
        "    distances=[calculate_distance(x, x_train, self.metric, self.cov_inv) for x_train in self.X_train]\n",
        "    #sort distance, returns indexes of the closest k\n",
        "    nearest_index=np.argsort(distances)[:self.k]\n",
        "    #supervised learning compares with true value, get value of closest\n",
        "    nearest_y_value=[self.y_train[i] for i in nearest_index]\n",
        "    if self.target=='regression' and self.dev==None:\n",
        "      self.dev=np.std(nearest_y_value)\n",
        "    #get y value depending on the target\n",
        "    return find_target(nearest_y_value, self.target)\n",
        "\n",
        "  def evaluate(self, y_pred, y_test, eval='accuracy', custom_dev=None):\n",
        "    if self.target == 'classification':\n",
        "      try:\n",
        "        if eval != 'accuracy':\n",
        "            raise ValueError(\"eval parameter is ignored in classification models, evaluation method is accuracy\")\n",
        "      except ValueError as e:\n",
        "        print(e)\n",
        "      try:\n",
        "        if custom_dev is not None:\n",
        "          raise ValueError(\"Deviation won't be used in classification models, parameter ignored\")\n",
        "      except ValueError as e:\n",
        "        print(e)\n",
        "      return class_accuracy(y_pred, y_test)\n",
        "    elif self.target == 'regression':\n",
        "        if eval == 'accuracy':\n",
        "            if custom_dev is not None:\n",
        "              if (not isinstance(custom_dev, int) or custom_dev <0) and (custom_dev is not None):\n",
        "                raise ValueError('Standard deviation must be a non-negative integer')\n",
        "              elif custom_dev >= (max(y_test) - min(y_test)):\n",
        "                raise ValueError(\"Deviation higher than y range, guaranteed 100% accuracy, no significance in results\")\n",
        "              self.dev=custom_dev\n",
        "            elif self.dev is None:\n",
        "                raise ValueError(\"For regression evaluation with 'accuracy', you must specify a non-negative deviation (dev).\")\n",
        "            elif self.dev >= (max(y_test) - min(y_test)):\n",
        "                raise ValueError(\"Deviation higher than y range, guaranteed 100% accuracy, no significance in results\")\n",
        "            else:\n",
        "              self.dev = self.dev\n",
        "            return reg_accuracy(y_pred, y_test, self.dev)\n",
        "        elif eval == 'score':\n",
        "            return mean_squared_error(y_pred, y_test)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid eval. Allowed evaluation methods are: 'accuracy' or 'score'\")\n",
        "    else:\n",
        "        raise ValueError(\"Invalid target. Allowed targets are 'classification' or 'regression'\")\n",
        "\n",
        "\n",
        "\n",
        "  def cross_validation(self, X, y, folds=5, eval='accuracy'): #cross validation for how well the model does splitting the data in different ways\n",
        "    shuffle_index=np.random.permutation(len(X))\n",
        "    fold_size=len(X)//folds\n",
        "    fold_index=[shuffle_index[i:i+fold_size] for i in range(0, len(X), fold_size)]\n",
        "    metrics=[]\n",
        "    for i in range(folds):\n",
        "      test_indices = fold_index[i]\n",
        "      train_indices = np.concatenate([fold_index[j] for j in range(folds) if j != i])\n",
        "      X_train = X[train_indices]\n",
        "      y_train = y[train_indices]\n",
        "      X_test = X[test_indices]\n",
        "      y_test = y[test_indices]\n",
        "      self.fit(X_train, y_train)\n",
        "      y_pred = self.predict(X_test)\n",
        "      metrics.append(self.evaluate(y_pred, y_test, eval))\n",
        "    return np.mean(metrics)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxr4TvBe1pni"
      },
      "source": [
        "## Education dataset\n",
        "kaggle classification set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwM8ZltNwaxS",
        "outputId": "0487198b-f0d8-4c07-d9e2-ae84a2b66409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Dataset can be manually uploaded by downloading it from kaggle and uploading it into colab\n",
        "#path='dataset.csv' #uncomment this code if dataset is in colab and check correct path\n",
        "#or with the following code if the dataset is saved in drive, if using previous code, comment following lines\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path='/content/drive/MyDrive/dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bq9v0dtnwRTH"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(path) #dataset saved in the df variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H31J7yM-G_RU",
        "outputId": "3bc5908d-130d-467b-fda3-6d47fac5c04f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Marital status                                      int64\n",
              "Application mode                                    int64\n",
              "Application order                                   int64\n",
              "Course                                              int64\n",
              "Daytime/evening attendance                          int64\n",
              "Previous qualification                              int64\n",
              "Nacionality                                         int64\n",
              "Mother's qualification                              int64\n",
              "Father's qualification                              int64\n",
              "Mother's occupation                                 int64\n",
              "Father's occupation                                 int64\n",
              "Displaced                                           int64\n",
              "Educational special needs                           int64\n",
              "Debtor                                              int64\n",
              "Tuition fees up to date                             int64\n",
              "Gender                                              int64\n",
              "Scholarship holder                                  int64\n",
              "Age at enrollment                                   int64\n",
              "International                                       int64\n",
              "Curricular units 1st sem (credited)                 int64\n",
              "Curricular units 1st sem (enrolled)                 int64\n",
              "Curricular units 1st sem (evaluations)              int64\n",
              "Curricular units 1st sem (approved)                 int64\n",
              "Curricular units 1st sem (grade)                  float64\n",
              "Curricular units 1st sem (without evaluations)      int64\n",
              "Curricular units 2nd sem (credited)                 int64\n",
              "Curricular units 2nd sem (enrolled)                 int64\n",
              "Curricular units 2nd sem (evaluations)              int64\n",
              "Curricular units 2nd sem (approved)                 int64\n",
              "Curricular units 2nd sem (grade)                  float64\n",
              "Curricular units 2nd sem (without evaluations)      int64\n",
              "Unemployment rate                                 float64\n",
              "Inflation rate                                    float64\n",
              "GDP                                               float64\n",
              "Target                                             object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2sPxFD89gFm"
      },
      "source": [
        "Encode the object variable so that the type instead of being an object is an int. And separate data frame into x values and y values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DBU1Oay59HNX"
      },
      "outputs": [],
      "source": [
        "y_encoder={'Target':{'Dropout':0, 'Graduate':1,'Enrolled':2}}\n",
        "y_df=df.replace(y_encoder)\n",
        "y_c=y_df['Target']\n",
        "X_c=df.drop(['Target'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "34lyfBld-ZTC"
      },
      "outputs": [],
      "source": [
        "set_distribution=0.75\n",
        "len_data=df.shape[0]\n",
        "len_train=int(len_data*set_distribution) #rounded\n",
        "index=np.arange(0,len_data)\n",
        "np.random.shuffle(index)\n",
        "X_train_c = X_c.iloc[index[:len_train]].to_numpy() #start 'till len_train\n",
        "y_train_c = y_c.iloc[index[:len_train]].to_numpy()\n",
        "X_test_c = X_c.iloc[index[len_train:]].to_numpy() #from len_train on\n",
        "y_test_c = y_c.iloc[index[len_train:]].to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY-JJ0cOklQJ"
      },
      "source": [
        "# Using the model for a non toy dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4ZZqO9D20c9"
      },
      "source": [
        "## Variations in k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVdbH9W8cajc",
        "outputId": "e1e5c864-ae75-4b44-c6da-282182bc720f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66.2748643761302\n",
            "67.26943942133815\n",
            "67.99276672694394\n",
            "Exception caught: k is bigger than the amount of data points, recreate KNN with a different k, or add more data\n"
          ]
        }
      ],
      "source": [
        "knn3=KNN(k=3)\n",
        "knn3.fit(X_train_c, y_train_c)\n",
        "y_pred=knn3.predict(X_test_c)\n",
        "print(knn3.evaluate(y_pred,y_test_c))\n",
        "\n",
        "knn5=KNN(k=5)\n",
        "knn5.fit(X_train_c, y_train_c)\n",
        "y_pred=knn5.predict(X_test_c)\n",
        "print(knn5.evaluate(y_pred,y_test_c))\n",
        "\n",
        "knn10=KNN(k=10)\n",
        "knn10.fit(X_train_c, y_train_c)\n",
        "y_pred=knn10.predict(X_test_c)\n",
        "print(knn10.evaluate(y_pred,y_test_c))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV_0hreJzAZZ"
      },
      "source": [
        "##Â Variations in metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T6X4-s50cem",
        "outputId": "474bcd35-b7e9-429a-d0a2-84534c08030a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67.26943942133815\n",
            "69.16817359855335\n",
            "70.97649186256781\n",
            "25.85895117540687\n"
          ]
        }
      ],
      "source": [
        "knn1=KNN(k=5,metric='euclidean') #euclidean distance\n",
        "knn1.fit(X_train_c, y_train_c)\n",
        "y_pred=knn1.predict(X_test_c)\n",
        "print(knn1.evaluate(y_pred,y_test_c))\n",
        "\n",
        "knn2=KNN(k=5,metric='manhattan') #manhattan distance\n",
        "knn2.fit(X_train_c, y_train_c)\n",
        "y_pred=knn2.predict(X_test_c)\n",
        "print(knn2.evaluate(y_pred,y_test_c))\n",
        "\n",
        "knn3=KNN(k=5,metric='mahalanobis') #mahalanobis distance\n",
        "knn3.fit(X_train_c, y_train_c)\n",
        "y_pred=knn3.predict(X_test_c)\n",
        "print(knn3.evaluate(y_pred,y_test_c))\n",
        "\n",
        "knn4=KNN(k=5,metric='cosine similarity') #cosine similarity distance\n",
        "knn4.fit(X_train_c, y_train_c)\n",
        "y_pred=knn4.predict(X_test_c)\n",
        "print(knn4.evaluate(y_pred,y_test_c))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing cross validation for the best parameters found"
      ],
      "metadata": {
        "id": "gM9_NhNosdFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=X_c.to_numpy()\n",
        "y=y_c.to_numpy()"
      ],
      "metadata": {
        "id": "LFAo3rfMIv-B"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_cv=KNN(k=10, metric='mahalanobis')\n",
        "knn_cv.cross_validation(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpIaisvkshiZ",
        "outputId": "cb42d64d-31bf-4ecf-de3b-d22a44da43f1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70.74660633484163"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}